{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Text Corrector\n",
    "\n",
    "The objective of this notebook is build a function that recibe as input any words and find the most similar world of an specific vocabulary.\n",
    "In this case the vocabulary are the words in a pdf file called `Data Science from Scratch- First Principles with Python`.\n",
    "\n",
    "We use the Levenshtein distance to find the closest word."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from collections import defaultdict,Counter\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import Levenshtein\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/dalopeza/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"punkt\")\n",
    "path_pdf=\"Data Science from Scratch- First Principles with Python.pdf\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to extract text from pdf file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_pdf(pdf_path):\n",
    "    text = \"\"\n",
    "    with open(pdf_path, \"rb\") as pdf_file:\n",
    "        pdf_reader = PyPDF2.PdfReader(pdf_file)\n",
    "        for page_num in range(17,len(pdf_reader.pages)):  #ignoring first 10 pages\n",
    "            text += pdf_reader.pages[page_num].extract_text()\n",
    "\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenazing text of pdf file to create the Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words_nltk = set(stopwords.words(\"english\"))\n",
    "def create_vocabulary(text):\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    tokens = [w for w in tokens if w.isalpha()]\n",
    "    tokens = [w for w in tokens if w not in stop_words_nltk]\n",
    "    vocabulary = set(tokens)\n",
    "    return vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating function to find the closest word in the vocabulary based on Levenshtein distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def auto_correct(input_string, vocabulary):\n",
    "    input_words = input_string.split()\n",
    "    corrected_words = []\n",
    "\n",
    "    for word in input_words:\n",
    "        # Find the closest word in the vocabulary based on Levenshtein distance\n",
    "        closest_word = min(vocabulary, key=lambda x: Levenshtein.distance(word, x))\n",
    "        corrected_words.append(closest_word)\n",
    "\n",
    "    corrected_string = ' '.join(corrected_words)\n",
    "    return corrected_string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execute the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to the words corrector program (type 'esc' or 'exit' to close the program)\n",
      "\n",
      "Enter a word: \n",
      "The closest word to helo is hero\n",
      "\n",
      "Enter a word: \n",
      "The closest word to helo is hero\n",
      "\n",
      "Enter a word: \n",
      "The closest word to macine is machine\n",
      "\n",
      "Enter a word: \n",
      "The closest word to macine lernin is machine learning\n",
      "\n",
      "Enter a word: \n",
      "The closest word to aprendizaje is predicate\n",
      "\n",
      "Enter a word: \n",
      "The closest word to artificial is artificial\n",
      "\n",
      "Enter a word: \n",
      "The closest word to artifical inteligencia is artificial intelligence\n",
      "\n",
      "Enter a word: \n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "vocabulary=create_vocabulary(\n",
    "                 extract_text_from_pdf(path_pdf)\n",
    "             )\n",
    "\n",
    "print(\"Welcome to the words corrector program (type 'esc' or 'exit' to close the program)\")\n",
    "\n",
    "while True:\n",
    "    print(\"\\nEnter a word: \")\n",
    "    input_string=input(\"Enter a word: \")\n",
    "    if input_string==\"exit\" or input_string==\"esc\":\n",
    "        break\n",
    "    else:\n",
    "        closest_word=auto_correct(input_string,vocabulary)\n",
    "        print(f'The closest word/sentence to \"{input_string}\" is \"{closest_word}\"')\n",
    "                   \n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.Text Suggestion \n",
    "\n",
    "Based on a few characters find the closest completed word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Build a Trie data structure for vocabulary\n",
    "class TrieNode:\n",
    "    def __init__(self):\n",
    "        self.children = defaultdict(TrieNode)\n",
    "        self.is_end_of_word = False\n",
    "\n",
    "def build_trie(vocabulary):\n",
    "    root = TrieNode()\n",
    "    for word in vocabulary:\n",
    "        node = root\n",
    "        for char in word:\n",
    "            node = node.children[char]\n",
    "        node.is_end_of_word = True\n",
    "    return root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Define a function to suggest words based on partial input using Trie\n",
    "def suggest_word(input_prefix, root):\n",
    "    input_prefix = input_prefix.lower()\n",
    "    \n",
    "    # Check if the input prefix is in the vocabulary\n",
    "    if input_prefix in vocabulary:\n",
    "        return input_prefix\n",
    "\n",
    "    node = root\n",
    "    for char in input_prefix:\n",
    "        if char in node.children:\n",
    "            node = node.children[char]\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    suggestions = []\n",
    "\n",
    "    def dfs(node, prefix):\n",
    "        if node.is_end_of_word:\n",
    "            suggestions.append(prefix)\n",
    "        for char, child_node in node.children.items():\n",
    "            dfs(child_node, prefix + char)\n",
    "\n",
    "    dfs(node, input_prefix)\n",
    "\n",
    "    if not suggestions:\n",
    "        return \"No matching words found\"\n",
    "    \n",
    "    # Count word frequencies and find the suggestion with the highest frequency\n",
    "    word_frequencies = Counter(vocabulary)\n",
    "    suggestion = max(suggestions, key=lambda x: word_frequencies[x])\n",
    "    return suggestion\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to the text suggestion program (type 'esc' or 'exit' to close the program)\n",
      "\n",
      "Enter some characters: \n",
      "The suggestion for 'sci' is 'science'\n",
      "\n",
      "Enter some characters: \n",
      "The suggestion for 'dat' is 'data'\n",
      "\n",
      "Enter some characters: \n",
      "The suggestion for 'dat' is 'data'\n",
      "\n",
      "Enter some characters: \n",
      "The suggestion for 'mach' is 'machine'\n",
      "\n",
      "Enter some characters: \n",
      "The suggestion for 'machine l' is 'machine l'\n",
      "\n",
      "Enter some characters: \n",
      "The suggestion for 'lear' is 'learn'\n",
      "\n",
      "Enter some characters: \n",
      "The suggestion for 'inte' is 'interpret'\n",
      "\n",
      "Enter some characters: \n",
      "The suggestion for 'expo' is 'exposition'\n",
      "\n",
      "Enter some characters: \n",
      "The suggestion for 'clas' is 'class'\n",
      "\n",
      "Enter some characters: \n",
      "The suggestion for 'reg' is 'regression'\n",
      "\n",
      "Enter some characters: \n",
      "The suggestion for 're' is 'regression'\n",
      "\n",
      "Enter some characters: \n",
      "The suggestion for 'log' is 'log'\n",
      "\n",
      "Enter some characters: \n",
      "The suggestion for 'logi' is 'logic'\n",
      "\n",
      "Enter some characters: \n",
      "The suggestion for 'logis' is 'logistic'\n",
      "\n",
      "Enter some characters: \n"
     ]
    }
   ],
   "source": [
    "# Build the Trie for the vocabulary\n",
    "trie_root = build_trie(vocabulary)\n",
    "\n",
    "print(\"Welcome to the text suggestion program (type 'esc' or 'exit' to close the program)\")\n",
    "\n",
    "while True:\n",
    "    print(\"\\nEnter some characters: \")\n",
    "    input_prefix=input(\"Enter some characters: \")\n",
    "    if input_prefix==\"exit\" or input_prefix==\"esc\":\n",
    "        break\n",
    "    else:\n",
    "        suggestion = suggest_word(input_prefix, trie_root)\n",
    "        print(f\"The suggestion for '{input_prefix}' is '{suggestion}'\")\n",
    "                   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Algebra_Taller1_Sebastian_David-Vxe6WzMv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
